{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\onkar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"Technology News\": [\n",
    "        \"https://techcrunch.com/\",\n",
    "        \"https://www.theverge.com/\",\n",
    "        \"https://www.wired.com/\"\n",
    "    ],\n",
    "    \"World News\": [\n",
    "        \"https://www.bbc.com/news/world\",\n",
    "        \"https://www.aljazeera.com/\",\n",
    "        \"https://apnews.com/hub/world-news\"\n",
    "    ],\n",
    "    \"Sports\": [\n",
    "        \"https://www.espn.com/\",\n",
    "        \"https://www.skysports.com/\",\n",
    "        \"https://www.bbc.com/sport\"\n",
    "    ],\n",
    "    \"Entertainment\": [\n",
    "        \"https://variety.com/\",\n",
    "        \"https://www.hollywoodreporter.com/\",\n",
    "        \"https://ew.com/\"\n",
    "    ],\n",
    "    \"Science\": [\n",
    "        \"https://www.scientificamerican.com/\",\n",
    "        \"https://phys.org/\",\n",
    "        \"https://www.livescience.com/\"\n",
    "    ],\n",
    "    \"Health\": [\n",
    "        \"https://www.webmd.com/\",\n",
    "        \"https://www.mayoclinic.org/\",\n",
    "        \"https://www.health.com/\"\n",
    "    ],\n",
    "    \"Business\": [\n",
    "        \"https://www.forbes.com/\",\n",
    "        \"https://www.cnbc.com/\",\n",
    "        \"https://www.ft.com/\"\n",
    "    ],\n",
    "    \"Politics\": [\n",
    "        \"https://www.npr.org/sections/politics/\",\n",
    "        \"https://www.bbc.com/news/politics\",\n",
    "        \"https://fivethirtyeight.com/\"\n",
    "    ],\n",
    "    \"Environment\": [\n",
    "        \"https://www.nationalgeographic.com/environment/\",\n",
    "        \"https://www.ecowatch.com/\",\n",
    "        \"https://www.treehugger.com/\"\n",
    "    ],\n",
    "    \"Education\": [\n",
    "        \"https://www.edweek.org/\",\n",
    "        \"https://www.insidehighered.com/\",\n",
    "        \"https://www.chronicle.com/\"\n",
    "    ],\n",
    "    \"Travel\": [\n",
    "        \"https://www.lonelyplanet.com/\",\n",
    "        \"https://www.roughguides.com/\",\n",
    "        \"https://www.cntraveler.com/\"\n",
    "    ],\n",
    "    \"Food\": [\n",
    "        \"https://www.epicurious.com/\",\n",
    "        \"https://www.allrecipes.com/\",\n",
    "        \"https://www.bonappetit.com/\"\n",
    "    ],\n",
    "    \"Fashion\": [\n",
    "        \"https://www.vogue.com/\",\n",
    "        \"https://www.elle.com/\",\n",
    "        \"https://www.harpersbazaar.com/\"\n",
    "    ],\n",
    "    \"Automotive\": [\n",
    "        \"https://www.caranddriver.com/\",\n",
    "        \"https://www.motortrend.com/\",\n",
    "        \"https://www.autocar.co.uk/\"\n",
    "    ],\n",
    "    \"Real Estate\": [\n",
    "        \"https://www.realtor.com/news/\",\n",
    "        \"https://www.redfin.com/blog/\",\n",
    "        \"https://www.trulia.com/blog/\"\n",
    "    ],\n",
    "    \"Personal Finance\": [\n",
    "        \"https://www.nerdwallet.com/\",\n",
    "        \"https://www.bankrate.com/\",\n",
    "        \"https://www.investopedia.com/\"\n",
    "    ],\n",
    "    \"Gaming\": [\n",
    "        \"https://www.ign.com/\",\n",
    "        \"https://www.gamespot.com/\",\n",
    "        \"https://kotaku.com/\"\n",
    "    ],\n",
    "    \"Parenting\": [\n",
    "        \"https://www.parents.com/\",\n",
    "        \"https://www.babycenter.com/\",\n",
    "        \"https://www.whattoexpect.com/\"\n",
    "    ],\n",
    "    \"DIY and Crafts\": [\n",
    "        \"https://www.instructables.com/\",\n",
    "        \"https://www.apartmenttherapy.com/\",\n",
    "        \"https://www.diyncrafts.com/\"\n",
    "    ],\n",
    "    \"Fitness\": [\n",
    "        \"https://www.bodybuilding.com/\",\n",
    "        \"https://www.menshealth.com/fitness/\",\n",
    "        \"https://www.shape.com/fitness\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=5)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    \n",
    "    title = soup.title.text if soup.title else \"No Title\"\n",
    "\n",
    "    \n",
    "    paragraphs = soup.find_all('p')\n",
    "    content = ' '.join([p.text for p in paragraphs])\n",
    "\n",
    "    return title, content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) \n",
    "    text = text.lower()  \n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data to a text file\n",
    "def save_to_file(category, text):\n",
    "    filename = f\"{category}.txt\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping category: Technology News\n",
      " Saved Technology News data (6375 characters)\n",
      "\n",
      "Scraping category: World News\n",
      " Saved World News data (4030 characters)\n",
      "\n",
      "Scraping category: Sports\n",
      " Saved Sports data (6330 characters)\n",
      "\n",
      "Scraping category: Entertainment\n",
      " Saved Entertainment data (4772 characters)\n",
      "\n",
      "Scraping category: Science\n",
      " Saved Science data (16062 characters)\n",
      "\n",
      "Scraping category: Health\n",
      " Saved Health data (1636 characters)\n",
      "\n",
      "Scraping category: Business\n",
      " Saved Business data (4981 characters)\n",
      "\n",
      "Scraping category: Politics\n",
      " Saved Politics data (8550 characters)\n",
      "\n",
      "Scraping category: Environment\n",
      " Saved Environment data (7829 characters)\n",
      "\n",
      "Scraping category: Education\n",
      " Saved Education data (3451 characters)\n",
      "\n",
      "Scraping category: Travel\n",
      " Saved Travel data (3415 characters)\n",
      "\n",
      "Scraping category: Food\n",
      " Saved Food data (1423 characters)\n",
      "\n",
      "Scraping category: Fashion\n",
      " Saved Fashion data (1571 characters)\n",
      "\n",
      "Scraping category: Automotive\n",
      " Saved Automotive data (3710 characters)\n",
      "\n",
      "Scraping category: Real Estate\n",
      " Saved Real Estate data (3022 characters)\n",
      "\n",
      "Scraping category: Personal Finance\n",
      " Saved Personal Finance data (6755 characters)\n",
      "\n",
      "Scraping category: Gaming\n",
      " Saved Gaming data (3973 characters)\n",
      "\n",
      "Scraping category: Parenting\n",
      " Saved Parenting data (6648 characters)\n",
      "\n",
      "Scraping category: DIY and Crafts\n",
      " Saved DIY and Crafts data (1478 characters)\n",
      "\n",
      "Scraping category: Fitness\n",
      " Saved Fitness data (8588 characters)\n",
      "\n",
      " Web scraping and text processing complete! Check the 'WebText-20' folder.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"WebText-20/raw_files\"):\n",
    "    os.makedirs(\"WebText-20/raw_files\")\n",
    "\n",
    "for category, urls in categories.items():\n",
    "    print(f\"\\nScraping category: {category}\")\n",
    "    all_text = \"\"\n",
    "\n",
    "    for url in urls:\n",
    "        title, content = scrape_website(url)\n",
    "        if content:\n",
    "            all_text += f\"\\nTitle: {title}\\nContent: {content}\\n\"\n",
    "\n",
    "    raw_file_path = os.path.join(\"WebText-20/raw_files\", f\"{category}_raw\")\n",
    "    save_to_file(raw_file_path, all_text)\n",
    "\n",
    "    cleaned_text = clean_text(all_text)\n",
    "\n",
    "    cleaned_file_path = os.path.join(\"WebText-20\", f\"{category}_cleaned\")\n",
    "    save_to_file(cleaned_file_path, cleaned_text)\n",
    "\n",
    "    print(f\" Saved {category} data ({len(cleaned_text)} characters)\")\n",
    "\n",
    "print(\"\\n Web scraping and text processing complete! Check the 'WebText-20' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
